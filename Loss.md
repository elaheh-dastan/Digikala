# MSE
It penalizes larger errors more heavily because of the squaring.

Sensitive to outliers

# MAE
- More robust to outliers than MSE.
- Has the same unit as the target variable (makes interpretation easier).

# RÂ² Score (Coefficient of Determination)
RÂ² tells you how much of the variance in the target variable is explained by your model.

![images/r2.png](images/r2.png)

Interpretation

- ğ‘…2=1: perfect predictions
- ğ‘…2=0: model predicts no better than the mean
- ğ‘…2<0: model is worse than predicting the mean

# Cross Entropy
Used for:
â†’ Classification tasks (predicting discrete categories like â€œelectronicsâ€, â€œclothingâ€, etc.)

What it measures:
â†’ How far the predicted probability distribution is from the true class distribution.

yi: one-hot true label

Where itâ€™s used:

- Classification (softmax output)
- Contrastive learning (after computing similarities + scaling + softmax)

Key property:

Itâ€™s sensitive to probabilities, not raw vector similarity.

## Multi-Label Classification
Softmax (used in normal cross entropy):

â†’ Forces all probabilities to sum to 1

â†’ Interprets labels as mutually exclusive

Thatâ€™s wrong for multi-label, because you can have multiple true labels. we treat each class as an independent yes/no (binary) problem.

Each class has its own sigmoid output, each class independently gets a loss, then we sum (or average) across all classes

| Setting          | Goal                           | Activation              | Loss                     |
| ---------------- | ------------------------------ | ----------------------- | ------------------------ |
| **Single-label** | Pick *one* best class          | **Softmax**             | Cross Entropy            |
| **Multi-label**  | Predict *all* relevant classes | **Sigmoid (per class)** | **Binary Cross Entropy** |



# Cosine Similarity
What it measures:

â†’ The angle between two vectors â€” not their magnitude.

Key property:

Itâ€™s a distance metric, not a loss function by itself.

# logit scale or (temperature)
When you use cosine similarity to compare embeddings (e.g., between queries and products), the values usually lie between -1 and 1.
Thatâ€™s a pretty small range â€” so when you apply softmax on those similarities, all the outputs look too similar (not â€œsharpâ€ enough).

To fix that, we scale the similarities before softmax


| Ï„ (temperature)     | Effect on softmax                                                | Interpretation                                         |
| ------------------- | ---------------------------------------------------------------- | ------------------------------------------------------ |
| **< 1** (e.g. 0.05) | **Sharper** â€” increases contrast between positives and negatives | Model becomes more confident (stronger peaks)          |
| **> 1** (e.g. 2.0)  | **Softer** â€” reduces contrast                                    | Model becomes less confident, spreads probability mass |
| **= 1**             | Neutral (default)                                                | Normal softmax                                         |


## Example

| Product       | Cosine sim |
| ------------- | ---------- |
| Correct match | 0.8        |
| Wrong match A | 0.6        |
| Wrong match B | 0.5        |

Without scaling (Ï„ = 1):

softmax([0.8,0.6,0.5])â‡’[0.42,0.34,0.24]

Model says the correct match is only 42% confident.

With Ï„ = 0.05:

softmax([16,12,10])â‡’[0.999,0.0002,0.00005]

Now the distribution is very sharp â€” the correct match is clearly dominant.

So, dividing by a small Ï„ (< 1) effectively amplifies differences between similarities.

In practice, many implementations (e.g., CLIP, Sentence-BERT) donâ€™t divide by Ï„, but instead learn a scaling parameter 

s=1/Ï„

If the model learns that all pairs are too close together, it increases ğ‘  (making the softmax sharper).

If things are too peaky and unstable, it decreases ğ‘ 

â€œtemperatureâ€ (Ï„) and â€œlogit scaleâ€ (s) are inverses of each other

Purpose: Makes softmax more discriminative over cosine sims, improves contrastive learning stability
